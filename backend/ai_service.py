import asyncio
import json
from typing import List, Dict, Any, AsyncGenerator, Optional
from dataclasses import asdict
import httpx
import openai
from anthropic import AsyncAnthropic

from config import Config, AIModelConfig

class AIService:
    def __init__(self, config: Config):
        self.config = config
        self._clients = {}
    
    def _get_client(self, model_config: AIModelConfig):
        """è·å–æˆ–åˆ›å»ºAIå®¢æˆ·ç«¯"""
        cache_key = f"{model_config.provider}_{model_config.name}"
        
        if cache_key not in self._clients:
            if model_config.provider == "volcengine":
                self._clients[cache_key] = openai.AsyncOpenAI(
                    api_key=model_config.api_key,
                    base_url=model_config.api_base
                )
            elif model_config.provider == "anthropic":
                self._clients[cache_key] = AsyncAnthropic(
                    api_key=model_config.api_key
                )
            elif model_config.provider == "ollama":
                self._clients[cache_key] = httpx.AsyncClient(
                    base_url=model_config.api_base or "http://localhost:11434"
                )
        
        return self._clients[cache_key]
    
    async def get_response(self, messages: List[Dict], model: str, selected_mcp: List[str] = None) -> str:
        """è·å–AIå“åº”ï¼ˆéæµå¼ï¼‰"""
        model_config = self.config.get_model_config(model)
        print(111,model_config)
        if not model_config:
            raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model}")
        
        # å¤„ç†MCPä¸Šä¸‹æ–‡
        enhanced_messages = await self._enhance_messages_with_mcp(messages, selected_mcp)
        
        if model_config.provider == "volcengine":
            return await self._get_openai_response(model_config, enhanced_messages)
        elif model_config.provider == "anthropic":
            return await self._get_anthropic_response(model_config, enhanced_messages)
        elif model_config.provider == "ollama":
            return await self._get_ollama_response(model_config, enhanced_messages)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {model_config.provider}")
    
    async def get_streaming_response(self, messages: List[Dict], model: str, selected_mcp: List[str] = None) -> AsyncGenerator[str, None]:
        """è·å–AIæµå¼å“åº”"""
        model_config = self.config.get_model_config(model)
        if not model_config:
            raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model}")
        
        # å¤„ç†MCPä¸Šä¸‹æ–‡
        enhanced_messages = await self._enhance_messages_with_mcp(messages, selected_mcp)
        
        # æ”¶é›†å®Œæ•´å“åº”ç”¨äºå‡½æ•°è°ƒç”¨æ£€æµ‹
        full_response = ""
        
        if model_config.provider == "volcengine":
            async for chunk in self._get_openai_streaming_response(model_config, enhanced_messages):
                if chunk:
                    full_response += chunk
                    yield chunk
        elif model_config.provider == "anthropic":
            async for chunk in self._get_anthropic_streaming_response(model_config, enhanced_messages):
                if chunk:
                    full_response += chunk
                    yield chunk
        elif model_config.provider == "ollama":
            async for chunk in self._get_ollama_streaming_response(model_config, enhanced_messages):
                if chunk:
                    full_response += chunk
                    yield chunk
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {model_config.provider}")
        
        # æ£€æŸ¥å¹¶å¤„ç†å‡½æ•°è°ƒç”¨
        if self._contains_function_call(full_response):
            async for function_result in self._execute_function_calls(full_response, selected_mcp):
                yield function_result
    
    def _contains_function_call(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å‡½æ•°è°ƒç”¨"""
        return "<|FunctionCallBegin|>" in text and "<|FunctionCallEnd|>" in text
    
    async def _execute_function_calls(self, text: str, selected_mcp: List[str]) -> AsyncGenerator[str, None]:
        """æ‰§è¡Œå‡½æ•°è°ƒç”¨å¹¶è¿”å›ç»“æœ"""
        import re
        import json
        
        # æå–å‡½æ•°è°ƒç”¨å†…å®¹
        pattern = r'<\|FunctionCallBegin\|\>(.*?)<\|FunctionCallEnd\|\>'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if not matches:
            return
        
        try:
            # å¯¼å…¥MCPæœåŠ¡
            from mcp_service import MCPService
            mcp_service = MCPService(self.config)
            
            yield "\n\n---\n\nğŸ”§ **æ­£åœ¨æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨...**\n\n"
            
            function_results = []  # æ”¶é›†æ‰€æœ‰å‡½æ•°è°ƒç”¨ç»“æœ
            
            for match in matches:
                try:
                    # è§£æJSONæ ¼å¼çš„å‡½æ•°è°ƒç”¨
                    function_calls = json.loads(match.strip())
                    if not isinstance(function_calls, list):
                        function_calls = [function_calls]
                    
                    for call in function_calls:
                        function_name = call.get("name")
                        parameters = call.get("parameters", {})
                        
                        yield f"ğŸ“ **è°ƒç”¨mcp**: `{function_name}`\n"
                        yield f"ğŸ“‹ **å‚æ•°**:\n```json\n{json.dumps(parameters, ensure_ascii=False, indent=2)}\n```\n\n"
                        
                        # æ‰§è¡Œå‡½æ•°è°ƒç”¨
                        try:
                            result = await self._call_mcp_function(
                                function_name, parameters, selected_mcp, mcp_service
                            )
                            
                            if result:
                                # æ˜¾ç¤ºæ ¼å¼åŒ–çš„ç»“æœ
                                if isinstance(result, dict):
                                    yield f"âœ… **æ‰§è¡ŒæˆåŠŸ**\n\n"
                                    yield await self._format_mcp_result(result, function_name)
                                elif isinstance(result, list):
                                    yield f"âœ… **æ‰§è¡ŒæˆåŠŸ** (è¿”å› {len(result)} æ¡è®°å½•)\n\n"
                                    yield await self._format_mcp_result(result, function_name)
                                elif isinstance(result, str):
                                    # å°è¯•è§£æå­—ç¬¦ä¸²ä¸º JSON
                                    try:
                                        parsed_result = json.loads(result)
                                        yield f"âœ… **æ‰§è¡ŒæˆåŠŸ**\n\n"
                                        yield await self._format_mcp_result(parsed_result, function_name)
                                        result = parsed_result  # ä½¿ç”¨è§£æåçš„ç»“æœ
                                    except json.JSONDecodeError:
                                        # å¦‚æœä¸æ˜¯ JSONï¼Œç›´æ¥æ˜¾ç¤ºæ–‡æœ¬
                                        yield f"âœ… **æ‰§è¡Œç»“æœ**:\n{result}\n\n"
                                else:
                                    yield f"âœ… **æ‰§è¡Œç»“æœ**:\n```json\n{json.dumps(result, ensure_ascii=False, indent=2)}\n```\n\n"
                                
                                # æ”¶é›†ç»“æœç”¨äºåç»­ AI å¤„ç†
                                function_results.append({
                                    "function_name": function_name,
                                    "parameters": parameters,
                                    "result": result
                                })
                            else:
                                yield f"âŒ **æ‰§è¡Œå¤±è´¥**: æœªæ‰¾åˆ°åŒ¹é…çš„MCPå‡½æ•°\n\n"
                        
                        except Exception as e:
                            yield f"âŒ **æ‰§è¡Œé”™è¯¯**: {str(e)}\n\n"
                
                except json.JSONDecodeError as e:
                    yield f"âŒ **JSONè§£æé”™è¯¯**: {str(e)}\n\n"
                except Exception as e:
                    yield f"âŒ **å‡½æ•°è°ƒç”¨å¤„ç†é”™è¯¯**: {str(e)}\n\n"
            
            # å¦‚æœæœ‰å‡½æ•°è°ƒç”¨ç»“æœï¼Œè®© AI åŸºäºç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”
            if function_results:
                yield "\n\n---\n\nğŸ¤– **AI åˆ†æç»“æœ...**\n\n"
                
                # æ„å»ºåŒ…å«å‡½æ•°è°ƒç”¨ç»“æœçš„æç¤º
                ai_prompt = self._build_analysis_prompt(function_results)
                
                # è°ƒç”¨ AI ç”ŸæˆåŸºäºç»“æœçš„å›ç­”
                async for analysis_chunk in self._get_ai_analysis(ai_prompt):
                    yield analysis_chunk
        
        except Exception as e:
            yield f"âŒ **å‡½æ•°è°ƒç”¨ç³»ç»Ÿé”™è¯¯**: {str(e)}\n\n"
    
    def _build_analysis_prompt(self, function_results: list) -> str:
        """æ„å»ºç”¨äº AI åˆ†æçš„æç¤º"""
        import json
        
        prompt = """è¯·åŸºäºä»¥ä¸‹å‡½æ•°è°ƒç”¨ç»“æœï¼Œç”¨è‡ªç„¶è¯­è¨€ä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä¸ªæ¸…æ™°ã€æœ‰ç”¨çš„å›ç­”ã€‚è¯·ï¼š

1. æ€»ç»“ä¸»è¦å‘ç°
2. æä¾›æœ‰ä»·å€¼çš„æ´å¯Ÿ
3. å¦‚æœæ˜¯æŸ¥è¯¢ç»“æœï¼Œçªå‡ºå…³é”®ä¿¡æ¯
4. ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­è¨€è¡¨è¾¾
5. ä¸è¦é‡å¤æ˜¾ç¤ºåŸå§‹æ•°æ®ï¼Œè€Œæ˜¯è¿›è¡Œåˆ†æå’Œè§£é‡Š

å‡½æ•°è°ƒç”¨ç»“æœï¼š

"""
        
        for i, func_result in enumerate(function_results, 1):
            prompt += f"## è°ƒç”¨ {i}: {func_result['function_name']}\n"
            prompt += f"å‚æ•°: {json.dumps(func_result['parameters'], ensure_ascii=False)}\n"
            prompt += f"ç»“æœ: {json.dumps(func_result['result'], ensure_ascii=False, indent=2)}\n\n"
        
        prompt += """
è¯·åŸºäºä»¥ä¸Šç»“æœç”Ÿæˆä¸€ä¸ªä¸“ä¸šã€æœ‰ç”¨çš„å›ç­”ã€‚
"""
        return prompt
    
    async def _get_ai_analysis(self, prompt: str) -> AsyncGenerator[str, None]:
        """è®© AI åˆ†æå‡½æ•°è°ƒç”¨ç»“æœå¹¶ç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”"""
        try:
            # ä½¿ç”¨å½“å‰é…ç½®çš„é»˜è®¤æ¨¡å‹
            default_model = self.config.get_default_model()
            model_config = self.config.get_model_config(default_model)
            
            if not model_config:
                yield "âš ï¸ æ— æ³•è·å– AI æ¨¡å‹é…ç½®ï¼Œæ— æ³•ç”Ÿæˆåˆ†æ\n"
                return
            
            # æ„å»ºåˆ†ææ¶ˆæ¯
            analysis_messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„å‡½æ•°è°ƒç”¨ç»“æœï¼Œç”Ÿæˆæ¸…æ™°ã€æœ‰ç”¨çš„è‡ªç„¶è¯­è¨€å›ç­”ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ]
            
            # è·å–æµå¼å“åº”
            if model_config.provider == "volcengine":
                async for chunk in self._get_openai_streaming_response(model_config, analysis_messages):
                    if chunk:
                        yield chunk
            elif model_config.provider == "anthropic":
                async for chunk in self._get_anthropic_streaming_response(model_config, analysis_messages):
                    if chunk:
                        yield chunk
            elif model_config.provider == "ollama":
                async for chunk in self._get_ollama_streaming_response(model_config, analysis_messages):
                    if chunk:
                        yield chunk
        
        except Exception as e:
            yield f"âš ï¸ AI åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\n"
    
    async def _format_mcp_result(self, result: dict, function_name: str) -> str:
        """æ ¼å¼åŒ– MCP è°ƒç”¨ç»“æœï¼Œæä¾›æ›´å‹å¥½çš„å±•ç¤º"""
        import json
        
        formatted_output = ""
        
        try:
            # å¯¹äºä¼ä¸šæŸ¥è¯¢ç±»ç»“æœçš„ç‰¹æ®Šå¤„ç†
            if function_name in ['search_companies', 'search_established_companies', 'search_selfemployed', 'search_established_selfemployed']:
                if isinstance(result, dict) and 'data' in result:
                    data = result['data']
                    if 'num_found' in data:
                        formatted_output += f"ğŸ“Š **æŸ¥è¯¢ç»Ÿè®¡**: å…±æ‰¾åˆ° **{data['num_found']:,}** æ¡è®°å½•\n\n"
                    
                    if 'data_list' in data and isinstance(data['data_list'], list):
                        formatted_output += f"ğŸ“‹ **ä¼ä¸šåˆ—è¡¨** (æ˜¾ç¤ºå‰ {min(len(data['data_list']), 10)} æ¡):\n\n"
                        for i, company in enumerate(data['data_list'][:10], 1):
                            formatted_output += f"**{i}. {company.get('companyName', 'æœªçŸ¥ä¼ä¸š')}**\n"
                            if 'establishDate' in company:
                                formatted_output += f"   ğŸ“… æˆç«‹æ—¶é—´: `{company['establishDate']}`\n"
                            if 'legalPerson' in company:
                                formatted_output += f"   ğŸ‘¤ æ³•å®šä»£è¡¨äºº: `{company['legalPerson']}`\n"
                            if 'capital' in company:
                                formatted_output += f"   ğŸ’° æ³¨å†Œèµ„æœ¬: `{company['capital']}`\n"
                            if 'companyStatusStr' in company:
                                formatted_output += f"   ğŸ“ˆ ä¼ä¸šçŠ¶æ€: `{company['companyStatusStr']}`\n"
                            if 'creditNo' in company:
                                formatted_output += f"   ğŸ†” ç»Ÿä¸€ä¿¡ç”¨ä»£ç : `{company['creditNo']}`\n"
                            formatted_output += "\n"
                        
                        if len(data['data_list']) > 10:
                            formatted_output += f"*... è¿˜æœ‰ {len(data['data_list']) - 10:,} æ¡è®°å½•*\n\n"
                
                # æ˜¾ç¤ºåˆ†é¡µä¿¡æ¯
                if isinstance(result, dict) and 'data' in result:
                    data = result['data']
                    if 'current_page' in data and 'total_page' in data:
                        formatted_output += f"ğŸ“„ **åˆ†é¡µä¿¡æ¯**: ç¬¬ {data['current_page']} é¡µï¼Œå…± {data['total_page']:,} é¡µ\n\n"
            
            # å¯¹äºä¼ä¸šåŸºæœ¬ä¿¡æ¯æŸ¥è¯¢çš„ç‰¹æ®Šå¤„ç†
            elif function_name == 'get_company_info':
                if isinstance(result, dict):
                    formatted_output += f"ğŸ¢ **ä¼ä¸šåŸºæœ¬ä¿¡æ¯**:\n\n"
                    info_fields = {
                        'CompanyName': ('ğŸ¢', 'ä¼ä¸šåç§°'),
                        'LegalPerson': ('ğŸ‘¤', 'æ³•å®šä»£è¡¨äºº'),
                        'EstablishDate': ('ğŸ“…', 'æˆç«‹æ—¶é—´'),
                        'Capital': ('ğŸ’°', 'æ³¨å†Œèµ„æœ¬'),
                        'CompanyType': ('ğŸ·ï¸', 'ä¼ä¸šç±»å‹'),
                        'CompanyStatus': ('ğŸ“ˆ', 'ä¼ä¸šçŠ¶æ€'),
                        'CompanyAddress': ('ğŸ ', 'ä¼ä¸šåœ°å€'),
                        'BusinessScope': ('ğŸ’¼', 'ç»è¥èŒƒå›´'),
                        'CreditNo': ('ğŸ†”', 'ç»Ÿä¸€ä¿¡ç”¨ä»£ç ')
                    }
                    
                    for field, (emoji, label) in info_fields.items():
                        if field in result and result[field]:
                            value = result[field]
                            if field == 'BusinessScope' and len(value) > 200:
                                value = value[:200] + "..."
                            formatted_output += f"{emoji} **{label}**: `{value}`\n"
                    formatted_output += "\n"
            
            # å¯¹äºé£é™©æŸ¥è¯¢çš„ç‰¹æ®Šå¤„ç†
            elif function_name == 'search_company_risk':
                if isinstance(result, dict):
                    formatted_output += f"âš ï¸ **ä¼ä¸šé£é™©ä¿¡æ¯**:\n\n"
                    risk_types = {
                        'self_risk': ('ğŸ”´', 'è‡ªæˆ‘é£é™©'),
                        'relation_risk': ('ğŸŸ¡', 'å…³è”é£é™©'),
                        'self_notice': ('â„¹ï¸', 'è‡ªèº«é‡è¦ä¿¡æ¯'),
                        'relation_notice': ('ğŸ“¢', 'å…³è”é‡è¦ä¿¡æ¯')
                    }
                    
                    for risk_type, (emoji, label) in risk_types.items():
                        if risk_type in result and result[risk_type].get('total', 0) > 0:
                            risk_data = result[risk_type]
                            formatted_output += f"{emoji} **{label}**: `{risk_data['total']}` æ¡è®°å½•\n"
                    formatted_output += "\n"
            
            # å¯¹äºç§‘åˆ›è¯„åˆ†çš„ç‰¹æ®Šå¤„ç†
            elif function_name == 'get_stie_score':
                if isinstance(result, dict):
                    formatted_output += f"ğŸ§¬ **ä¼ä¸šç§‘åˆ›èƒ½åŠ›è¯„ä¼°**:\n\n"
                    if 'company_name' in result:
                        formatted_output += f"ğŸ¢ **ä¼ä¸šåç§°**: `{result['company_name']}`\n"
                    if 'score' in result:
                        formatted_output += f"ğŸ“Š **ç§‘åˆ›è¯„åˆ†**: `{result['score']}`\n"
                    if 'level' in result:
                        formatted_output += f"ğŸ† **ç§‘åˆ›ç­‰çº§**: `{result['level']}`\n"
                    formatted_output += "\n"
            
            # å¯¹äºé€šç”¨æŸ¥è¯¢ç»“æœçš„å¤„ç†
            else:
                if isinstance(result, dict):
                    # æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
                    if 'statusCode' in result:
                        status_emoji = "âœ…" if result['statusCode'] == 1 else "âŒ"
                        status_text = "æˆåŠŸ" if result['statusCode'] == 1 else "å¤±è´¥"
                        formatted_output += f"{status_emoji} **æŸ¥è¯¢çŠ¶æ€**: `{status_text}`\n"
                    
                    if 'statusMessage' in result:
                        formatted_output += f"ğŸ“ **çŠ¶æ€ä¿¡æ¯**: `{result['statusMessage']}`\n\n"
            
            # æ€»æ˜¯åœ¨æœ€åæ˜¾ç¤ºç¾è§‚çš„å®Œæ•´ JSON æ•°æ®
            formatted_output += f"ğŸ” **å®Œæ•´æ•°æ®**:\n```json\n{json.dumps(result, ensure_ascii=False, indent=2)}\n```\n\n"
            
        except Exception as e:
            # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹ JSON æ˜¾ç¤º
            formatted_output = f"âš ï¸ **æ•°æ®æ ¼å¼åŒ–å¤±è´¥**: `{str(e)}`\n\n"
            formatted_output += f"ğŸ“„ **åŸå§‹æ•°æ®**:\n```json\n{json.dumps(result, ensure_ascii=False, indent=2)}\n```\n\n"
        
        return formatted_output
    
    async def _call_mcp_function(self, function_name: str, parameters: dict, selected_mcp: List[str], mcp_service) -> dict:
        """åœ¨é€‰ä¸­çš„MCPä¸­æŸ¥æ‰¾å¹¶æ‰§è¡Œå‡½æ•°"""
        for mcp_value in selected_mcp:
            try:
                # è·å–è¯¥MCPçš„å·¥å…·åˆ—è¡¨
                tools = await mcp_service.get_mcp_tools(mcp_value)
                
                # æ£€æŸ¥å‡½æ•°æ˜¯å¦å­˜åœ¨äºè¯¥MCPä¸­
                function_exists = any(tool.get("name") == function_name for tool in tools)
                
                if function_exists:
                    # æ‰§è¡ŒMCPå‡½æ•°è°ƒç”¨
                    result = await mcp_service.execute_mcp_function(mcp_value, function_name, parameters)
                    return result
            
            except Exception as e:
                print(f"MCP {mcp_value} æ‰§è¡Œå‡½æ•° {function_name} å¤±è´¥: {e}")
                continue
        
        return None
    
    async def _enhance_messages_with_mcp(self, messages: List[Dict], selected_mcp: List[str] = None) -> List[Dict]:
        """ä½¿ç”¨MCPå¢å¼ºæ¶ˆæ¯"""
        if not selected_mcp:
            return messages
        
        # ç¡®ä¿ messages æ˜¯å­—å…¸åˆ—è¡¨æ ¼å¼
        enhanced_messages = []
        for msg in messages:
            if hasattr(msg, 'model_dump'):  # Pydantic å¯¹è±¡
                enhanced_messages.append(msg.model_dump())
            elif hasattr(msg, 'dict'):  # æ—§ç‰ˆ Pydantic
                enhanced_messages.append(msg.dict())
            else:  # å·²ç»æ˜¯å­—å…¸
                enhanced_messages.append(msg)
        
        # æ„å»ºè¯¦ç»†çš„MCPå·¥å…·ä¸Šä¸‹æ–‡
        mcp_context = """ä½ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹MCPå·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ã€‚å½“éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š

<|FunctionCallBegin|>
[{"name": "å·¥å…·åç§°", "parameters": {"å‚æ•°å": "å‚æ•°å€¼"}}]
<|FunctionCallEnd|>

å¯ç”¨çš„MCPå·¥å…·ï¼š

"""
        
        for mcp_value in selected_mcp:
            mcp_config = self.config.get_mcp_config(mcp_value)
            if mcp_config:
                mcp_context += f"## {mcp_config.label} ({mcp_value})\n"
                mcp_context += f"æè¿°: {mcp_config.description}\n\n"
                
                # è·å–è¯¦ç»†çš„å·¥å…·åˆ—è¡¨
                try:
                    tools = await asyncio.wait_for(
                        self._get_mcp_tools_safe(mcp_config), 
                        timeout=5.0  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°5ç§’
                    )
                    if tools:
                        for tool in tools:
                            tool_name = tool.get('name', 'unknown')
                            tool_desc = tool.get('description', 'æ— æè¿°')
                            tool_params = tool.get('parameters', {})
                            
                            mcp_context += f"### {tool_name}\n"
                            mcp_context += f"åŠŸèƒ½: {tool_desc}\n"
                            
                            # æ·»åŠ å‚æ•°ä¿¡æ¯
                            if tool_params and isinstance(tool_params, dict):
                                properties = tool_params.get('properties', {})
                                required = tool_params.get('required', [])
                                if properties:
                                    mcp_context += "å‚æ•°:\n"
                                    for param_name, param_info in properties.items():
                                        param_type = param_info.get('type', 'string')
                                        param_desc = param_info.get('description', param_info.get('title', ''))
                                        is_required = param_name in required
                                        required_mark = " (å¿…éœ€)" if is_required else " (å¯é€‰)"
                                        mcp_context += f"  - {param_name} ({param_type}){required_mark}: {param_desc}\n"
                            
                            # æ·»åŠ è°ƒç”¨ç¤ºä¾‹
                            mcp_context += f"è°ƒç”¨ç¤ºä¾‹: <|FunctionCallBegin|>[{{\"name\": \"{tool_name}\", \"parameters\": {{}}}}]<|FunctionCallEnd|>\n\n"
                    else:
                        mcp_context += "å·¥å…·åŠ è½½ä¸­ï¼Œè¯·ç¨å...\n\n"
                except asyncio.TimeoutError:
                    mcp_context += "å·¥å…·åŠ è½½è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•\n\n"
                except Exception as e:
                    mcp_context += f"å·¥å…·åŠ è½½å¤±è´¥: {str(e)}\n\n"
        
        mcp_context += """
é‡è¦æç¤ºï¼š
1. å½“ç”¨æˆ·è¯¢é—®éœ€è¦æŸ¥è¯¢æ•°æ®æ—¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·
2. è°ƒç”¨å·¥å…·å‰ï¼Œè¯·ç¡®ä¿å‚æ•°æ­£ç¡®ä¸”å®Œæ•´
3. å¿…éœ€å‚æ•°ä¸èƒ½ä¸ºç©ºï¼Œå¯é€‰å‚æ•°å¯ä»¥çœç•¥æˆ–è®¾ä¸ºnull
4. æ¯æ¬¡åªè°ƒç”¨ä¸€ä¸ªå·¥å…·ï¼Œç­‰å¾…ç»“æœåå†å†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨å…¶ä»–å·¥å…·
5. è°ƒç”¨å·¥å…·åï¼Œè¯·æ ¹æ®è¿”å›çš„ç»“æœå‘ç”¨æˆ·æä¾›æœ‰ç”¨çš„ä¿¡æ¯
"""
        
        # å¦‚æœç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯ç³»ç»Ÿæ¶ˆæ¯ï¼Œåˆ™è¿½åŠ MCPä¸Šä¸‹æ–‡
        if enhanced_messages and enhanced_messages[0].get("role") == "system":
            enhanced_messages[0]["content"] += f"\n\n{mcp_context}"
        else:
            # å¦åˆ™åœ¨å¼€å¤´æ’å…¥ç³»ç»Ÿæ¶ˆæ¯
            enhanced_messages.insert(0, {
                "role": "system",
                "content": mcp_context
            })
        
        return enhanced_messages
    
    async def _get_openai_response(self, model_config: AIModelConfig, messages: List[Dict]) -> str:
        """è·å–OpenAIå“åº”"""
        client = self._get_client(model_config)
        
        try:
            response = await client.chat.completions.create(
                model=model_config.model_id,
                messages=messages,
                max_tokens=model_config.max_tokens,
                temperature=model_config.temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            raise Exception(f"OpenAI API è°ƒç”¨å¤±è´¥: {str(e)}")
    
    async def _get_openai_streaming_response(self, model_config: AIModelConfig, messages: List[Dict]) -> AsyncGenerator[str, None]:
        """è·å–OpenAIæµå¼å“åº”"""
        client = self._get_client(model_config)
        
        try:
            stream = await client.chat.completions.create(
                model=model_config.model_id,
                messages=messages,
                max_tokens=model_config.max_tokens,
                temperature=model_config.temperature,
                stream=True
            )
            
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
        except Exception as e:
            raise Exception(f"OpenAI Streaming API è°ƒç”¨å¤±è´¥: {str(e)}")
    
    async def _get_anthropic_response(self, model_config: AIModelConfig, messages: List[Dict]) -> str:
        """è·å–Anthropicå“åº”"""
        client = self._get_client(model_config)
        
        try:
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼ï¼ˆAnthropicè¦æ±‚ä¸åŒçš„æ ¼å¼ï¼‰
            system_message = ""
            user_messages = []
            
            for msg in messages:
                if msg["role"] == "system":
                    system_message = msg["content"]
                else:
                    user_messages.append(msg)
            
            response = await client.messages.create(
                model=model_config.model_id,
                max_tokens=model_config.max_tokens,
                temperature=model_config.temperature,
                system=system_message,
                messages=user_messages
            )
            
            return response.content[0].text
        except Exception as e:
            raise Exception(f"Anthropic API è°ƒç”¨å¤±è´¥: {str(e)}")
    
    async def _get_anthropic_streaming_response(self, model_config: AIModelConfig, messages: List[Dict]) -> AsyncGenerator[str, None]:
        """è·å–Anthropicæµå¼å“åº”"""
        client = self._get_client(model_config)
        
        try:
            # è½¬æ¢æ¶ˆæ¯æ ¼å¼
            system_message = ""
            user_messages = []
            
            for msg in messages:
                if msg["role"] == "system":
                    system_message = msg["content"]
                else:
                    user_messages.append(msg)
            
            async with client.messages.stream(
                model=model_config.model_id,
                max_tokens=model_config.max_tokens,
                temperature=model_config.temperature,
                system=system_message,
                messages=user_messages
            ) as stream:
                async for chunk in stream.text_stream:
                    yield chunk
        except Exception as e:
            raise Exception(f"Anthropic Streaming API è°ƒç”¨å¤±è´¥: {str(e)}")
    
    async def _get_ollama_response(self, model_config: AIModelConfig, messages: List[Dict]) -> str:
        """è·å–Ollamaå“åº”"""
        client = self._get_client(model_config)
        
        try:
            response = await client.post("/api/chat", json={
                "model": model_config.model_id,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": model_config.temperature,
                    "num_predict": model_config.max_tokens
                }
            })
            response.raise_for_status()
            return response.json()["message"]["content"]
        except Exception as e:
            raise Exception(f"Ollama API è°ƒç”¨å¤±è´¥: {str(e)}")
    
    async def _get_ollama_streaming_response(self, model_config: AIModelConfig, messages: List[Dict]) -> AsyncGenerator[str, None]:
        """è·å–Ollamaæµå¼å“åº”"""
        client = self._get_client(model_config)
        
        try:
            async with client.stream("POST", "/api/chat", json={
                "model": model_config.model_id,
                "messages": messages,
                "stream": True,
                "options": {
                    "temperature": model_config.temperature,
                    "num_predict": model_config.max_tokens
                }
            }) as response:
                response.raise_for_status()
                async for line in response.aiter_lines():
                    if line:
                        data = json.loads(line)
                        if "message" in data and "content" in data["message"]:
                            yield data["message"]["content"]
        except Exception as e:
            raise Exception(f"Ollama Streaming API è°ƒç”¨å¤±è´¥: {str(e)}")
    
    async def _get_mcp_tools_safe(self, mcp_config):
        """å®‰å…¨è·å– MCP å·¥å…·åˆ—è¡¨ï¼Œä¸é˜»å¡ä¸»æµç¨‹"""
        try:
            from mcp_service import MCPService
            mcp_service = MCPService(self.config)
            return await mcp_service.get_mcp_tools(mcp_config.value)
        except Exception:
            return []
    
    def is_healthy(self) -> bool:
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®
            available_models = self.config.get_available_models()
            return len([m for m in available_models if m["available"]]) > 0
        except Exception:
            return False 